# Docker Compose Production Override
# Usage: docker compose -f docker-compose.yaml -f docker-compose.prod.yml up -d

version: '3.8'

services:
  # API service production configuration
  api:
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    restart: unless-stopped
    environment:
      # Production optimizations
      DEPLOY_ENV: PRODUCTION
      DEBUG: false
      FLASK_DEBUG: false
      LOG_LEVEL: INFO
      SERVER_WORKER_AMOUNT: 4
      SERVER_WORKER_CLASS: gevent
      SERVER_WORKER_CONNECTIONS: 20
      GUNICORN_TIMEOUT: 600
      # Security
      WEB_API_CORS_ALLOW_ORIGINS: https://your-domain.com
      CONSOLE_CORS_ALLOW_ORIGINS: https://your-domain.com
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Worker service production configuration
  worker:
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'
        reservations:
          memory: 1.5G
          cpus: '1.0'
    restart: unless-stopped
    environment:
      DEPLOY_ENV: PRODUCTION
      DEBUG: false
      LOG_LEVEL: INFO
      CELERY_WORKER_AMOUNT: 4
      CELERY_AUTO_SCALE: true
      CELERY_MAX_WORKERS: 8
      CELERY_MIN_WORKERS: 2
    healthcheck:
      test: ["CMD", "celery", "-A", "app.celery", "inspect", "ping"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Web service production configuration
  web:
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    restart: unless-stopped
    environment:
      NODE_ENV: production
      NEXT_TELEMETRY_DISABLED: 1
      PM2_INSTANCES: 4
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Dashboard service production configuration
  dashboard:
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Database production configuration
  db:
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    restart: unless-stopped
    command: >
      postgres -c max_connections=300
               -c shared_buffers=2GB
               -c work_mem=16MB
               -c maintenance_work_mem=512MB
               -c effective_cache_size=6GB
               -c checkpoint_completion_target=0.9
               -c wal_buffers=32MB
               -c default_statistics_target=100
               -c random_page_cost=1.1
               -c effective_io_concurrency=200
               -c min_wal_size=1GB
               -c max_wal_size=4GB
               -c max_worker_processes=8
               -c max_parallel_workers_per_gather=4
               -c max_parallel_workers=8
               -c max_parallel_maintenance_workers=4
    environment:
      # Performance tuning
      POSTGRES_INITDB_ARGS: "--data-checksums --encoding=UTF8 --locale=C"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -U postgres -d dify"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Redis production configuration
  redis:
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    restart: unless-stopped
    command: >
      redis-server 
      --requirepass ${REDIS_PASSWORD:-difyai123456}
      --maxmemory 1536mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --rdbcompression yes
      --rdbchecksum yes
      --tcp-keepalive 300
      --timeout 0
      --tcp-backlog 511
      --databases 16
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Nginx production configuration
  nginx:
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    restart: unless-stopped
    environment:
      # Production nginx settings
      NGINX_WORKER_PROCESSES: auto
      NGINX_WORKER_CONNECTIONS: 4096
      NGINX_CLIENT_MAX_BODY_SIZE: 100M
      NGINX_KEEPALIVE_TIMEOUT: 65
      NGINX_PROXY_READ_TIMEOUT: 3600s
      NGINX_PROXY_SEND_TIMEOUT: 3600s
      NGINX_GZIP_ENABLED: true
      NGINX_GZIP_COMP_LEVEL: 6
      NGINX_RATE_LIMIT_ENABLED: true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Sandbox production configuration
  sandbox:
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    restart: unless-stopped
    environment:
      GIN_MODE: release
      WORKER_TIMEOUT: 30
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8194/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Plugin daemon production configuration
  plugin_daemon:
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5002/health"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # SSRF Proxy production configuration
  ssrf_proxy:
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

# Production networks
networks:
  default:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
  ssrf_proxy_network:
    driver: bridge
    internal: true

# Production volumes with specific configurations
volumes:
  db_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./volumes/db/data
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./volumes/redis/data
  app_storage:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./volumes/app/storage
